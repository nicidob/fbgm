{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.linear_model import LinearRegression,Ridge,ElasticNet,ElasticNetCV,LassoCV,SGDRegressor,RidgeCV\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import os, sys\n",
    "\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgt, spd, hpw, con, eye for offense\n",
    "# hgt, spd, (field gnd, fly, thr), (catcher's cat), (pitcher's ppw, ctrl, mov, end)\n",
    "# off - def = pts_scored\n",
    "# for each team\n",
    "off_cols = ['hgt', 'spd', 'hpw', 'con', 'eye']\n",
    "\n",
    "dbs_cols = ['hgt','spd']\n",
    "fld_cols = ['gnd','fly','thr']\n",
    "cat_cols = ['cat']\n",
    "ptc_cols = ['ppw','ctl','mov','endu']\n",
    "\n",
    "def_cols = dbs_cols + fld_cols + cat_cols + ptc_cols\n",
    "def_idx = {k:i for i,k in enumerate(def_cols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xso = []\n",
    "scores = []\n",
    "for file in sorted(os.listdir('.')):\n",
    "    if fnmatch.fnmatch(file, 'ZGMB_League*.json'):\n",
    "        print(file)\n",
    "        data = json.load(open(file,'rt',encoding='utf-8-sig'))\n",
    "\n",
    "        player_ratings = {}\n",
    "\n",
    "        for p in data['players']:\n",
    "            for r in p['ratings']:\n",
    "                player_ratings[(p['pid'],r['season'])] ={k:v for k,v in r.items() if type(v) == int and k != 'season'}\n",
    "\n",
    "        for g in data['games']:\n",
    "            season = g['season']\n",
    "            if g['won']['tid'] == g['teams'][0]['tid']: #home team won\n",
    "                pt_t = ( g['won']['pts'] , g['lost']['pts'] )\n",
    "            else:\n",
    "                pt_t = ( g['lost']['pts'] , g['won']['pts'] )\n",
    "\n",
    "            r2 = []\n",
    "            for tid_l in range(2):\n",
    "                off_w = []\n",
    "                off_r = []\n",
    "\n",
    "                def_w = []\n",
    "                def_r = []\n",
    "\n",
    "                for p in g['teams'][tid_l]['players']:\n",
    "                    rt = player_ratings[(p['pid'],g['season'])] \n",
    "                    pos = p['pos']\n",
    "                    pa = p['pa']/4\n",
    "                    bf = p['bf']/27\n",
    "                    def_r_p = np.zeros(len(def_cols))\n",
    "                    def_w_p = 0*np.ones(len(def_cols))\n",
    "\n",
    "                    if pa > 0: # offensive contrib\n",
    "                        off_w.append(pa)\n",
    "                        off_r.append([pa*rt[_] for _ in off_cols])\n",
    "                        if 'P' != pos and 'DH' != pos: # fielding contrib\n",
    "                            for c in dbs_cols + fld_cols:\n",
    "                                i = def_idx[c]\n",
    "                                def_w_p[i] += pa\n",
    "                                def_r_p[i] += pa*rt[c]\n",
    "                            if pos == 'C':\n",
    "                                for c in cat_cols:\n",
    "                                    i = def_idx[c]\n",
    "                                    def_w_p[i] += pa\n",
    "                                    def_r_p[i] += pa*rt[c]\n",
    "                    if bf > 0: # pitching contribu\n",
    "                        for c in ptc_cols:\n",
    "                            i = def_idx[c]\n",
    "                            def_w_p[i] += bf\n",
    "                            def_r_p[i] += bf*rt[c]\n",
    "                    if def_w_p.sum() > 0:\n",
    "                        def_w.append(def_w_p)\n",
    "                        def_r.append(def_r_p)\n",
    "                off_vec = (np.array(off_r)).sum(axis=0)/np.sum(off_w)\n",
    "                def_vec = (np.array(def_r)).sum(axis=0)/np.sum(def_w,axis=0)\n",
    "\n",
    "                row_vec = list(off_vec) + list(-def_vec)\n",
    "                y_vec = pt_t[tid_l]\n",
    "                Xso.append(row_vec)\n",
    "                scores.append(y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs[0],Xs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xs = np.nan_to_num(Xso,0)\n",
    "fx = StandardScaler()\n",
    "X2 = fx.fit_transform(Xs)\n",
    "y = np.array(scores).astype(float)\n",
    "\n",
    "reg = ElasticNetCV(l1_ratio=[.1,.4,.5,.7,.725,.75,.775,.8,.9],cv=3,n_alphas=250,positive=False,max_iter=2e4,fit_intercept=True)#(alpha=0.1,l1_ratio=0.7)#CV(cv=10)#ElasticNetCV(.7,cv=10,)\n",
    "#reg = ElasticNet(1e-3,0.01,positive=True,max_iter=2e4)#(alpha=0.1,l1_ratio=0.7)#CV(cv=10)#ElasticNetCV(.7,cv=10,)\n",
    "\n",
    "#reg = lgb.LGBMRegressor()\n",
    "reg.fit(X2,y)\n",
    "print(X2.shape,reg.score(X2,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.scatter(reg.predict(X2),y,s=5,alpha=0.1)\n",
    "#plt.ylim(-60,60)\n",
    "#plt.xlim(-60,60)\n",
    "plt.xlabel('predicted margin')\n",
    "plt.ylabel('actual margin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lbl = ['off_' + _ for _ in off_cols] + ['def_' + _ for _ in def_cols] \n",
    "filt_lbl = exp_lbl\n",
    "sorted([(np.round(i,3),n) for i,n in zip(reg.coef_,exp_lbl)],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X3f = pd.DataFrame(Xs,columns=filt_lbl)\n",
    "X3 = sm.add_constant(X3f)\n",
    "est = sm.OLS(y, X3)\n",
    "est2 = est.fit()\n",
    "est2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('home field adv is {:.1f} points'.format(reg.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_use = defaultdict(dict)\n",
    "for pos in ['off','def']:\n",
    "    res = sorted([(r,n,p) for n,r,p in zip(filt_lbl,est2.params[1:],est2.pvalues[1:]) if pos+ '_' in n],reverse=True)\n",
    "    print(pos+' : { ')\n",
    "    for p in res:\n",
    "        if np.linalg.norm(p[0]) > 1e-3 and p[2] < 0.05:\n",
    "            key = p[1].split('_')[1]\n",
    "            future_use[pos][key]  = p[0]\n",
    "            print('\\t{}: [{:.3f}, 1],'.format(key,p[0]))\n",
    "    print('},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_to_use = [k for k,v in (est2.pvalues < 0.1).items() if v if k != 'const']\n",
    "reg_small = ElasticNetCV(positive=True,cv=3)\n",
    "reg_small.fit(Xs[:,[list(filt_lbl).index(r) for r in ratings_to_use]],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sorted([(abs(v),k) for k,v in zip(ratings_to_use,reg_small.coef_)],reverse=True)\n",
    "for v,k in res:\n",
    "    print('{}\\t{}\\t{:.3f}'.format('',k,v))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pos = set([k.split('_')[0] for k in ratings_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_use = defaultdict(dict)\n",
    "for pos in sorted(list(valid_pos)):\n",
    "    res = sorted([(r,n) for n,r in zip(exp_lbl,reg.coef_) if pos+ '_' in n and r > 0],reverse=True)\n",
    "    print(pos+' : { ')\n",
    "    for p in res:\n",
    "        if np.linalg.norm(p[0]) > 1e-3:\n",
    "            #future_use[row[0]][res[i][1]] = row[1][res[i][1]]\n",
    "            print('\\t{}: [{:.3f}, 1],'.format(p[1].split('_')[1],p[0]))\n",
    "    print('},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
